<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models | LLM Security Group 's Notes</title><meta name="author" content="LLM Security Group"><meta name="copyright" content="LLM Security Group"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="英文题目：《A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models》 中文题目：《大型语言模型中幻觉缓解技术的综合综述》 发布于： arxiv 级别：无 论文链接： https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2401.01313  摘要 随着大型语言模型（LLMs）在编写类人文本">
<meta property="og:type" content="article">
<meta property="og:title" content="A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models">
<meta property="og:url" content="https://fdreamer2002.github.io/2025/08/11/%E5%8F%A4%E4%B9%89%E7%BF%94/2025-08-10/A-Comprehensive-Survey-of-Hallucination-Mitigation-Techniques-in-Large-Language-Models/index.html">
<meta property="og:site_name" content="LLM Security Group &#39;s Notes">
<meta property="og:description" content="英文题目：《A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models》 中文题目：《大型语言模型中幻觉缓解技术的综合综述》 发布于： arxiv 级别：无 论文链接： https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2401.01313  摘要 随着大型语言模型（LLMs）在编写类人文本">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://fdreamer2002.github.io/img/butterfly-icon.png">
<meta property="article:published_time" content="2025-08-11T02:29:08.000Z">
<meta property="article:modified_time" content="2025-09-01T09:17:24.394Z">
<meta property="article:author" content="LLM Security Group">
<meta property="article:tag" content="RAG">
<meta property="article:tag" content="监督微调">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://fdreamer2002.github.io/img/butterfly-icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
  "url": "https://fdreamer2002.github.io/2025/08/11/%E5%8F%A4%E4%B9%89%E7%BF%94/2025-08-10/A-Comprehensive-Survey-of-Hallucination-Mitigation-Techniques-in-Large-Language-Models/",
  "image": "https://fdreamer2002.github.io/img/butterfly-icon.png",
  "datePublished": "2025-08-11T02:29:08.000Z",
  "dateModified": "2025-09-01T09:17:24.394Z",
  "author": [
    {
      "@type": "Person",
      "name": "古义翔",
      "url": "https://fdreamer2002.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://fdreamer2002.github.io/2025/08/11/%E5%8F%A4%E4%B9%89%E7%BF%94/2025-08-10/A-Comprehensive-Survey-of-Hallucination-Mitigation-Techniques-in-Large-Language-Models/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":"ture","top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/EmoryHuang/BlogBeautify@1.1/scroll.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/EmoryHuang/BlogBeautify@1.1/gradient.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.7.0/style.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fontsource/jetbrains-mono@4.5.12/index.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><meta name="generator" content="Hexo 7.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">99</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">98</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">28</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><span> 类别分类</span></a></li><li><a class="site-page child" href="/authors/"><span> 作者分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">LLM Security Group 's Notes</span></a><a class="nav-page-title" href="/"><span class="site-name">A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><span> 类别分类</span></a></li><li><a class="site-page child" href="/authors/"><span> 作者分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-08-11T02:29:08.000Z" title="发表于 2025-08-11 10:29:08">2025-08-11</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-09-01T09:17:24.394Z" title="更新于 2025-09-01 17:17:24">2025-09-01</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%B9%BB%E8%A7%89%E7%BC%93%E8%A7%A3/">幻觉缓解</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><div class="note success flat"><p>英文题目：《A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models》</p>
<p>中文题目：《大型语言模型中幻觉缓解技术的综合综述》</p>
<p>发布于： arxiv</p>
<p>级别：无</p>
<p>论文链接： <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2401.01313">https://arxiv.org/pdf/2401.01313</a></p>
</div>
<h2 id="摘要">摘要</h2>
<p>随着大型语言模型（LLMs）在编写类人文本方面的能力不断提高，一个关键挑战仍然存在，即它们倾向于“幻觉”——生成看起来是事实但没有根据的内容。这种幻觉问题可以说是将这些强大的LLM安全地部署到影响人们生活的真实生产系统中的最大障碍。在实际环境中广泛采用LLM的道路在很大程度上取决于解决和减轻幻觉。与专注于有限任务的传统人工智能系统不同，LLM在训练期间接触了大量的在线文本数据。虽然这使它们能够表现出令人印象深刻的语言流畅性，但也意味着它们能够从训练数据中的偏差中推断信息，误解模糊的提示，或修改信息以使其表面上与输入对齐。当我们依赖语言生成能力进行敏感应用时，例如总结医疗记录、客户支持对话、财务分析报告以及提供错误的法律建议，这变得非常令人担忧。小错误可能会导致伤害，揭示了LLM缺乏实际理解，尽管在自学习方面取得了进展。本文对为减轻LLM中的幻觉而开发的32多种技术进行了全面调查。其中值得注意的是检索增强生成（RAG）（Lewis et al., 2021）、知识检索（Varshney et al., 2023）、CoNLI（Lei et al., 2023）和CoVe（Dhuliawala et al., 2023）。此外，我们引入了一个详细的分类法，根据各种参数（例如数据集利用率、常见任务、反馈机制和检索器类型）对这些方法进行分类。这种分类有助于区分专门设计用于解决LLM中幻觉问题的各种方法。此外，我们分析了这些技术中固有的挑战和局限性，为未来研究解决LLM领域内的幻觉和相关现象提供了坚实的基础。</p>
<h2 id="本文聚焦的问题">本文聚焦的问题</h2>
<p>本文聚焦的核心问题是大型语言模型（LLMs）的 “幻觉” 现象 —— 即模型生成看似合理但缺乏事实依据的错误内容，这一问题成为阻碍其在医疗记录总结、金融分析、法律建议等敏感领域安全部署的关键障碍。具体而言，文章关注幻觉产生的原因（如训练数据中的偏见、对模糊提示的误解读、缺乏实时信息更新等），并围绕如何系统地缓解这一现象展开，旨在通过梳理现有技术、构建分类体系，为解决幻觉问题提供全面的理论基础和实践指导。</p>
<h2 id="本文提出的方法">本文提出的方法</h2>
<p><img src="https://cdn.jsdelivr.net/gh/fdreamer2002/MyPics/blog/imgimage-20250811104951978.png" alt="image-20250811104951978"></p>
<p>LLM 中幻觉缓解技术的分类，重点介绍涉及模型开发和提示技术的主流方法。模型开发分为多种方法，包括新的解码策略、基于知识图的优化、添加新的损失函数组件以及监督式微调。同时，提示工程可以涉及基于检索增强的方法、基于反馈的策略或提示调整。<br>
Prompt engineering is the process of experimenting with various instructions to get the best output possible from an AI text generation model (White et al., 2023). In terms of hallucination mitigation, this process can provide speciﬁc context and expected outcomes (Feldman et al., 2023). The prompt engineering mitigation techniques can be outlined as follows:<br>
一是检索增强生成（RAG），分生成前（借外部模块、动态更新提示增知识）、生成中（实时检测修正、分步检索等）、生成后（依检索证据改输出、换高不确定性词）及端到端 RAG（联合训练检索与生成器）；二是自我优化，借反馈推理（像自验证流程、结构化比较等）让模型自查自纠；三是提示调整，靠轻量检索器、合成任务优化提示，提升表现并减少幻觉。<br>
Some papers focused on developing novel models to mitigate hallucinations. It is an ongoing and evolving process requiring a combination of algorithmic advancements and data quality improvements. Instead of going for ﬁne-tuning models, the following techniques implemented whole model architecture to tackle hallucinations. These techniques can be categorized as follows:<br>
新解码策略，借对比分布、干预注意力等增强输出真实性；知识图谱利用，融合实体关系、用自动化工具验证事实；基于忠实度的损失函数，借正则化、指标加权优化训练；监督微调，结合知识注入、反事实数据等，量化并降低幻觉，还能让模型拒答超知识范围问题。</p>
<h2 id="阅读总结">阅读总结</h2>
<p><strong>优点：</strong></p>
<ol>
<li>提示工程：灵活，无需改模型架构，快速适配场景；</li>
<li>成本低，不重训模型；可快速试错迭代，组合优化策略。</li>
</ol>
<p><strong>缺点：</strong></p>
<ol>
<li>提示工程：依赖检索质量（如RAG类方法，外部知识库的质量）；仅调输入输出，难解决深层幻觉；策略效果不稳定，跨任务和模型差异大。</li>
<li>模型开发：计算成本高；开发难，需深入模型架构，易引发新问题；领域适配差，跨领域需重调。</li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://fdreamer2002.github.io">古义翔</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://fdreamer2002.github.io/2025/08/11/%E5%8F%A4%E4%B9%89%E7%BF%94/2025-08-10/A-Comprehensive-Survey-of-Hallucination-Mitigation-Techniques-in-Large-Language-Models/">https://fdreamer2002.github.io/2025/08/11/%E5%8F%A4%E4%B9%89%E7%BF%94/2025-08-10/A-Comprehensive-Survey-of-Hallucination-Mitigation-Techniques-in-Large-Language-Models/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://fdreamer2002.github.io" target="_blank">LLM Security Group 's Notes</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/RAG/">RAG</a><a class="post-meta__tags" href="/tags/%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/">监督微调</a></div><div class="post-share"><div class="social-share" data-image="/img/butterfly-icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/08/11/%E5%8F%A4%E4%B9%89%E7%BF%94/2025-08-10/Enhanced-Language-Model-Truthfulness-with-Learnable-Intervention-and-Uncertainty-Expression/" title="Enhanced Language Model Truthfulness with Learnable Intervention and Uncertainty Expression"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Enhanced Language Model Truthfulness with Learnable Intervention and Uncertainty Expression</div></div><div class="info-2"><div class="info-item-1">英文题目：《Enhanced Language Model Truthfulness with Learnable Intervention and Uncertainty Expression》 中文题目：《通过可学习干预和不确定性表达的增强语言模型真实性》 发布于： arxiv 级别：无 论文链接： https://arxiv.org/pdf/2405.00301  摘要 大语言模型（LLMs）能够生成长篇连贯的文本，但它们常常会产生事实幻觉，这削弱了其可靠性。为缓解这一问题，推理阶段的方法会将大语言模型的表征导向之前为获取真相而学习到的 “真实方向”。然而，以相同强度应用这些真实方向无法在不同的查询上下文之间实现泛化。我们提出了LITO，一种用于真实性优化的可学习干预方法，它能自动识别针对每个特定上下文量身定制的最佳干预强度。LITO基于不断增加的干预强度探索一系列模型生成结果。当预测高度不确定时，它会选择最准确的回答或拒绝回答。在多个大语言模型和问答数据集上进行的实验表明，LITO在保持任务准确性的同时提高了真实性。LITO的自适应特性克服了一刀切干预方法的局限性，仅在模...</div></div></div></a><a class="pagination-related" href="/2025/08/11/%E6%B8%B8%E4%BF%8A%E7%88%BD/2025-08-10/X-Teaming-Multi-Turn-Jailbreaks-and-Defenses-with-Adaptive-Multi-Agents/" title="X-Teaming: Multi-Turn Jailbreaks and Defenses with Adaptive Multi-Agents"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">X-Teaming: Multi-Turn Jailbreaks and Defenses with Adaptive Multi-Agents</div></div><div class="info-2"><div class="info-item-1">英文题目：《X-Teaming: Multi-Turn Jailbreaks and Defenses with Adaptive Multi-Agents》 中文题目：《X-Teaming：使用自适应多代理进行多回合越狱和防御》 发布于：arxiv 级别：无 论文链接： https://arxiv.org/pdf/2504.13203  摘要 与语言模型 （LM） 的多轮交互会带来严重的安全风险，因为有害意图可能会战略性地在交易所之间传播。然而，绝大多数先前的工作都集中在单弯安全上，而适应性和多样性仍然是多弯红队的主要挑战之一。为了应对这些挑战，我们提出了 X-Teaming，这是一个可扩展的框架，它系统地探索看似无害的交互如何升级为有害结果并生成相应的攻击场景。X-Teaming 采用协作代理进行规划、攻击优化和验证，实现了最先进的多轮越狱有效性和多样性，在具有代表性的领先开权重和闭源模型中成功率高达 98.1%。特别是，X-Teaming 在最新的 Claude 3.7 Sonnet 模型中实现了 96.2% 的攻击成功率，该模型被认为几乎不受单回合攻击的影响。在 X-Te...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/08/19/%E6%B8%B8%E4%BF%8A%E7%88%BD/2025-08-23/Highlight%20&%20Summarize%20RAG%20without%20the%20jailbreaks/" title="Highlight &amp; Summarize: RAG without the jailbreaks"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-19</div><div class="info-item-2">Highlight &amp; Summarize: RAG without the jailbreaks</div></div><div class="info-2"><div class="info-item-1">英文题目：《Highlight &amp; Summarize: RAG without the jailbreaks》 中文题目：《高亮与总结：无需担心越狱问题的检索增强生成》 论文作者：Giovanni Cherubin,  Andrew Paverd 发布于： arxiv 发布时间：2025-08-04 级别：无 论文链接： https://doi.org/10.48550/arXiv.2508.02872 论文代码：https://github.com/microsoft/highlight-summarize  摘要 防止大型语言模型（LLMs）的越狱和模型劫持是一项重要但具有挑战性的任务。例如，在与聊天机器人交互时，恶意用户可能输入精心设计的提示词，促使大语言模型生成不良内容或执行与其预期用途完全不同的任务。针对此类攻击的现有缓解措施通常依赖于强化大语言模型的系统提示词，或使用经过训练的内容分类器来检测不良内容或离题对话。然而，由于可能的输入和不良输出空间非常庞大，这些概率性方法相对容易被绕过。 在本文中，我们提出并评估了 “高亮与总结”（H&amp;S），这是一种用...</div></div></div></a><a class="pagination-related" href="/2025/10/29/%E4%BC%8D%E4%BF%8A/2025-11-01/RAIDX%20A%20Retrieval-Augmented%20Generation%20and%20GRPO%20Reinforcement%20Learning%20Framework%20for%20Explainable%20Deepfake%20Detection/" title="RAIDX: A Retrieval-Augmented Generation and GRPO Reinforcement Learning Framework for Explainable Deepfake Detection"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-29</div><div class="info-item-2">RAIDX: A Retrieval-Augmented Generation and GRPO Reinforcement Learning Framework for Explainable Deepfake Detection</div></div><div class="info-2"><div class="info-item-1">英文题目：《RAIDX: A Retrieval-Augmented Generation and GRPO Reinforcement Learning Framework for Explainable Deepfake Detection》 中文题目：《RAIDX：一种用于可解释深度伪造检测的检索增强生成和GRPO强化学习框架》 论文作者： Tianxiao Li, Zhenglin Huang, Haiquan Wen, Yiwei He, Shuchang Lyu, Baoyuan Wu, Guangliang Cheng 发布于：MM ’25: Proceedings of the 33rd ACM International Conference on Multimedia 发布时间：2025-05-20 级别：CCF-A 论文链接：https://doi.org/10.1145/3746027.3754798 论文代码：暂无  摘要 人工智能生成模型的快速发展使得超逼真图像的创建成为可能，但也因此引发了广泛的虚假信息传播，带来了伦理风险。目前，...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">LLM Security Group</div><div class="author-info-description">分享知识，认识世界</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">99</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">98</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">28</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%AC%E6%96%87%E8%81%9A%E7%84%A6%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">2.</span> <span class="toc-text">本文聚焦的问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%AC%E6%96%87%E6%8F%90%E5%87%BA%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">3.</span> <span class="toc-text">本文提出的方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%98%85%E8%AF%BB%E6%80%BB%E7%BB%93"><span class="toc-number">4.</span> <span class="toc-text">阅读总结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/14/%E6%B8%B8%E4%BF%8A%E7%88%BD/2025-11-17/When%20LLM%20Meets%20DRL%20Advancing%20Jailbreaking%20Efficiency%20via%20DRL-guided%20Search/" title="When LLM Meets DRL: Advancing Jailbreaking Efficiency via DRL-guided Search">When LLM Meets DRL: Advancing Jailbreaking Efficiency via DRL-guided Search</a><time datetime="2025-11-14T08:58:14.000Z" title="发表于 2025-11-14 16:58:14">2025-11-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/12/%E6%B8%B8%E4%BF%8A%E7%88%BD/2025-11-17/GPTFuzzer%20Red%20Teaming%20Large%20Language%20Models%20with%20Auto-Generated%20Jailbreak%20Prompts/" title="GPTFuzzer: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts">GPTFuzzer: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts</a><time datetime="2025-11-12T08:08:14.000Z" title="发表于 2025-11-12 16:08:14">2025-11-12</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/11/%E4%BC%8D%E4%BF%8A/2025-11-14/Towards%20Modern%20Image%20Manipulation%20Localization%20%20A%20Large-Scale%20Dataset%20and%20Novel%20Methods/" title="Towards Modern Image Manipulation Localization:  A Large-Scale Dataset and Novel Methods">Towards Modern Image Manipulation Localization:  A Large-Scale Dataset and Novel Methods</a><time datetime="2025-11-11T11:53:16.000Z" title="发表于 2025-11-11 19:53:16">2025-11-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/11/%E6%B8%B8%E4%BF%8A%E7%88%BD/2025-11-17/GPT-4%20Is%20Too%20Smart%20To%20Be%20Safe%20Stealthy%20Chat%20with%20LLMs%20via%20Cipher/" title="GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher">GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher</a><time datetime="2025-11-11T04:51:14.000Z" title="发表于 2025-11-11 12:51:14">2025-11-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/10/%E4%BC%8D%E4%BF%8A/2025-11-14/Mesoscopic%20Insights%20Orchestrating%20Multi-scale%20&amp;%20Hybrid%20Architecture%20for%20Image%20Manipulation%20Localization/" title="Mesoscopic Insights: Orchestrating Multi-scale &amp; Hybrid Architecture for Image Manipulation Localization">Mesoscopic Insights: Orchestrating Multi-scale &amp; Hybrid Architecture for Image Manipulation Localization</a><time datetime="2025-11-10T11:53:16.000Z" title="发表于 2025-11-10 19:53:16">2025-11-10</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 By LLM Security Group</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.3</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script></div><script src="https://cdn.jsdelivr.net/gh/EmoryHuang/BlogBeautify@1.1/DynamicRibbon.min.js"></script><script src="https://cdn.jsdelivr.net/gh/EmoryHuang/BlogBeautify@1.1/star.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="输入关键词…" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>