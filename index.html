<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>LLM Security Group 's Notes - 分享知识，认识世界</title><meta name="author" content="LLM Security Group"><meta name="copyright" content="LLM Security Group"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="分享知识，认识世界">
<meta property="og:type" content="website">
<meta property="og:title" content="LLM Security Group &#39;s Notes">
<meta property="og:url" content="https://fdreamer2002.github.io/index.html">
<meta property="og:site_name" content="LLM Security Group &#39;s Notes">
<meta property="og:description" content="分享知识，认识世界">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://fdreamer2002.github.io/img/butterfly-icon.png">
<meta property="article:author" content="LLM Security Group">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://fdreamer2002.github.io/img/butterfly-icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "WebSite",
  "name": "LLM Security Group 's Notes",
  "url": "https://fdreamer2002.github.io/"
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://fdreamer2002.github.io/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":"ture","top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'LLM Security Group \'s Notes',
  isHighlightShrink: false,
  isToc: false,
  pageType: 'home'
}</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/EmoryHuang/BlogBeautify@1.1/scroll.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/EmoryHuang/BlogBeautify@1.1/gradient.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.7.0/style.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fontsource/jetbrains-mono@4.5.12/index.min.css"><meta name="generator" content="Hexo 7.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">77</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">81</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">28</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><span> 类别分类</span></a></li><li><a class="site-page child" href="/authors/"><span> 作者分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> 关于</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">LLM Security Group 's Notes</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><span> 类别分类</span></a></li><li><a class="site-page child" href="/authors/"><span> 作者分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="site-info"><h1 id="site-title">LLM Security Group 's Notes</h1></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts nc" id="recent-posts"><div class="recent-post-items"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/10/26/%E6%B8%B8%E4%BF%8A%E7%88%BD/2025-10-27/Multi-Turn%20Jailbreaking%20Large%20Language%20Models%20via%20Attention%20Shifting/" title="Multi-Turn Jailbreaking Large Language Models via Attention Shifting">Multi-Turn Jailbreaking Large Language Models via Attention Shifting</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-26T04:58:14.000Z" title="发表于 2025-10-26 12:58:14">2025-10-26</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%B6%8A%E7%8B%B1%E6%94%BB%E5%87%BB/">越狱攻击</a></span></div><div class="content">英文题目：《Multi-Turn Jailbreaking Large Language Models via Attention Shifting》 中文题目：《通过注意力转移对大型语言模型进行多轮越狱攻击》 论文作者：Xiaohu Du, Fan Mo, Ming Wen, Tu Gu, Huadi Zheng, Hai Jin, Jie Shi 发布于： AAAI-25 发布时间：2025-04-11 级别：CCF-A 论文链接：https://doi.org/10.1609/aaai.v39i22.34553 论文代码：无  摘要 大型语言模型（LLM）在各种自然语言处理任务中取得了显着的性能，但也带来了安全和道德威胁，因此需要红队和对齐过程来加强它们的安全性。为了有效利用这些对齐的LLM，最近的研究引入了基于多轮对话的越狱攻击。这些攻击旨在通过上下文内容引导LLM生成有害或有偏见的内容。然而，多轮越狱有效性的根本原因仍然不清楚。现有的攻击通常侧重于优化查询和升级毒性以构建对话，缺乏对LLM固有漏洞的彻底分析。在本文中，我们首先对单轮越狱和多轮越狱之间的差异进行了深入分析...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/10/26/%E5%8F%A4%E4%B9%89%E7%BF%94/2025-10-27/Images%20are%20Achilles%E2%80%99%20Heel%20of%20Alignment%20Exploiting%20Visual%20Vulnerabilities%20for%20Jailbreaking%20Multimodal%20Large%20Language%20Models/" title="Images are Achilles’ Heel of Alignment: Exploiting Visual Vulnerabilities for Jailbreaking Multimodal Large Language Models">Images are Achilles’ Heel of Alignment: Exploiting Visual Vulnerabilities for Jailbreaking Multimodal Large Language Models</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-25T16:00:00.000Z" title="发表于 2025-10-26 00:00:00">2025-10-26</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%B6%8A%E7%8B%B1%E6%94%BB%E5%87%BB/">越狱攻击</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%B6%8A%E7%8B%B1%E6%94%BB%E5%87%BB/%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/">模型安全</a></span></div><div class="content">英文题目：《Images are Achilles’ Heel of Alignment: Exploiting Visual Vulnerabilities for Jailbreaking Multimodal Large Language Models》 中文题目：《图像是多模态对齐的阿喀琉斯之踵：利用视觉漏洞实现多模态大语言模型越狱》 论文作者：Yifan Li, Hangyu Guo, Kun Zhou, Wayne Xin Zhao, Ji-Rong Wen 单位：中国人民大学高瓴人工智能学院、信息学院、北京大数据管理与分析方法重点实验室 发布于：ECCV 2024（CCF B） 论文链接：https://arxiv.org/abs/2403.09792 代码链接：https://github.com/RUCAIBox/HADES  摘要 本文研究多模态大型语言模型（MLLMs）的安全对齐问题。我们对代表性MLLMs的无害性表现进行了系统性实证分析，发现图像输入会引发模型的对齐漏洞。基于此，我们提出名为hades的新型越狱方法，通过精心设计的图像隐藏并放大文本输入中的...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/10/25/%E5%8F%A4%E4%B9%89%E7%BF%94/2025-10-27/Distraction%20is%20All%20You%20Need%20for%20Multimodal%20Large%20Language%20Model%20Jailbreaking/" title="Distraction is All You Need for Multimodal Large Language Model Jailbreaking">Distraction is All You Need for Multimodal Large Language Model Jailbreaking</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-24T16:00:00.000Z" title="发表于 2025-10-25 00:00:00">2025-10-25</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/">模型安全</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/%E8%B6%8A%E7%8B%B1%E6%94%BB%E5%87%BB/">越狱攻击</a></span></div><div class="content">英文题目：《Distraction is All You Need for Multimodal Large Language Model Jailbreaking》 中文题目：《分散即一切：面向多模态大语言模型的越狱攻击方法研究》 论文作者：Zuopeng Yang, Jiluan Fan, Anli Yan, Erdun Gao, Xin Lin, Tao Li, Kanghua Mo, Changyu Dong 单位：广州大学、上海交通大学、阿德莱德大学 发布于：CVPR-2025（CCF  A） 发布时间：2025年2月 论文链接：https://arxiv.org/abs/2502.10794 代码链接：https://github.com/TeamPigeonLab/CS-DJ   摘要 多模态大语言模型（MLLMs）结合视觉与文本模态，展现了强大的跨模态理解能力，但复杂的视觉-文本交互也可能引入新的安全漏洞。本文提出了分散假设（Distraction Hypothesis），认为越狱攻击的关键并非图像内容本身，而是输入的复杂度与多样性对模型注意力的干扰作用。 基于此...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/10/21/%E4%BC%8D%E4%BF%8A/2025-10-24/SIDA%20Social%20Media%20Image%20Deepfake%20Detection,%20Localization%20and%20Explanation/" title="SIDA: Social Media Image Deepfake Detection, Localization and Explanation with Large Multimodal Model">SIDA: Social Media Image Deepfake Detection, Localization and Explanation with Large Multimodal Model</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-21T11:53:16.000Z" title="发表于 2025-10-21 19:53:16">2025-10-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%9B%BE%E5%83%8F%E4%BC%AA%E9%80%A0%E6%A3%80%E6%B5%8B/">图像伪造检测</a></span></div><div class="content">英文题目：《Social Media Image Deepfake Detection, Localization and Explanation with Large Multimodal Model》 中文题目：《SIDA:基于大型多模态模型对社交媒体图像深度伪造检测、定位与解释》 论文作者：Zhenglin Huang，Jinwei Hu，Xiangtai Li，Xiangtai Li，Xingyu Zhao，Bei Peng，Baoyuan Wu，Xiaowei Huang，Guangliang Cheng 发布于：CVPR 发布时间：2025-06 级别：CCF-A 论文链接： 10.1109/CVPR52734.2025.02685 论文代码：https://github.com/hzlsaber/SIDA  摘要 生成模型在创建高度逼真图像方面的快速进展， 对错误信息传播构成了重大风险。例如，当合成图像在社交媒体上分享时，可能会误导大量受众并侵蚀对数字内容的信任，导致严重后果。尽管取得了一些进展，学术界尚未为社交媒体创建一个大型且多样化的 深度伪...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/10/21/%E4%BC%8D%E4%BF%8A/2025-10-24/Generalized%20Diffusion%20Detector%20Mining%20Robust%20Features%20from%20Diffusion%20Models%20%20for%20Domain-Generalized%20Detection/" title="Generalized Diffusion Detector Mining Robust Features from Diffusion Models  for Domain-Generalized Detection">Generalized Diffusion Detector Mining Robust Features from Diffusion Models  for Domain-Generalized Detection</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-21T11:53:16.000Z" title="发表于 2025-10-21 19:53:16">2025-10-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%9B%BE%E5%83%8F%E4%BC%AA%E9%80%A0%E6%A3%80%E6%B5%8B/">图像伪造检测</a></span></div><div class="content">英文题目：《Generalized Diffusion Detector Mining Robust Features from Diffusion Models for Domain-Generalized Detection》 中文题目：《广义扩散检测器：从扩散模型中挖掘出鲁棒的特征，用于领域广义检测》 论文作者：Boyong He; Yuxiang Ji; Qianwen Ye; Zhuoyue Tan; Liaoni Wu 发布于：CVPR 发布时间：2025-06 级别：CCF-A 论文链接： 10.1109/CVPR52734.2025.00927 论文代码：[heboyong/Generalized-Diffusion-Detector: CVPR2025] Generalized Diffusion Detector: Mining Robust Features from Diffusion Models for Domain-Generalized Detection  摘要 领域泛化 (DG) 目标检测旨在提升检测器在未见过场景下的性能。...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/10/21/%E4%BC%8D%E4%BF%8A/2025-10-24/Language-guided%20Hierarchical%20Fine-grained%20Image%20Forgery/" title="Language-guided Hierarchical Fine-grained Image Forgery Detection and Localization">Language-guided Hierarchical Fine-grained Image Forgery Detection and Localization</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-21T11:53:16.000Z" title="发表于 2025-10-21 19:53:16">2025-10-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%9B%BE%E5%83%8F%E4%BC%AA%E9%80%A0%E6%A3%80%E6%B5%8B/">图像伪造检测</a></span></div><div class="content">英文题目：《Language-guided Hierarchical Fine-grained Image Forgery Detection and Localization》 中文题目：《语言引导的分层细粒度图像伪造检测与定位》 论文作者：Xiao Guo，Xiaohong Liu，Iacopo Masi，Xiaoming Liu 发布于：IJCV 发布时间：2025-12-10 级别：CCF-A 论文链接： https://doi.org/10.1007/s11263-024-02255-9 论文代码：https://github.com/CHELSEA234/HiFi_IFDL  摘要 CNN 合成和图像编辑领域生成的图像的伪造属性差异很大，这种差异使得统一的图像伪造检测和定位 (IFDL) 具有挑战性。为此，我们提出了一种用于 IFDL 表示学习的分层细粒度公式。具体而言，我们首先用不同级别的多个标签表示被篡改图像的伪造属性。然后，我们利用它们之间的层次依赖关系在这些级别上进行细粒度分类。因此，该算法能够学习全面的特征和不同伪造属性固有的层次结构，从...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/10/20/%E6%9D%8E%E8%B7%AF%E8%B7%AF/2025-10-20/FAKESHIELD%20EXPLAINABLE%20IMAGE%20FORGERY%20DETECTION%20AND%20LOCALIZATION%20VIA%20MULTI-MODAL%20LARGE%20LANGUAGE%20MODELS/" title="FAKESHIELD: EXPLAINABLE IMAGE FORGERY DETECTION AND LOCALIZATION VIA MULTI-MODAL LARGE LANGUAGE MODELS">FAKESHIELD: EXPLAINABLE IMAGE FORGERY DETECTION AND LOCALIZATION VIA MULTI-MODAL LARGE LANGUAGE MODELS</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-20T08:00:21.000Z" title="发表于 2025-10-20 16:00:21">2025-10-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%9B%BE%E5%83%8F%E4%BC%AA%E9%80%A0%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%AE%9A%E4%BD%8D/">图像伪造检测与定位</a></span></div><div class="content">   </div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/10/20/%E6%98%93%E5%AD%90%E6%96%87/%E7%AE%97%E6%B3%95%E7%B2%BE%E8%AF%BB/%E5%AF%B9%E6%8A%97%E6%80%A7%E6%94%BB%E5%87%BB%E6%A6%82%E8%BF%B0/" title="对抗性攻击概述">对抗性攻击概述</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-20T08:00:21.000Z" title="发表于 2025-10-20 16:00:21">2025-10-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AF%B9%E6%8A%97%E6%80%A7%E6%94%BB%E5%87%BB%E6%A6%82%E8%BF%B0/">对抗性攻击概述</a></span></div><div class="content">   </div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/10/20/%E6%9D%8E%E8%B7%AF%E8%B7%AF/2025-10-20/Towards%20General%20Visual-Linguistic%20Face%20Forgery%20Detection%20/" title="Towards General Visual-Linguistic Face Forgery Detection">Towards General Visual-Linguistic Face Forgery Detection</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-20T08:00:21.000Z" title="发表于 2025-10-20 16:00:21">2025-10-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%9B%BE%E5%83%8F%E4%BC%AA%E9%80%A0%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%AE%9A%E4%BD%8D/">图像伪造检测与定位</a></span></div><div class="content">   </div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/10/20/%E6%98%93%E5%AD%90%E6%96%87/2025-10-20/Adaptive-Perturbation-for-Adversarial-Attack/" title="’Adaptive Perturbation for Adversarial Attack'">’Adaptive Perturbation for Adversarial Attack'</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-19T16:00:00.000Z" title="发表于 2025-10-20 00:00:00">2025-10-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Adversarial-attack/">Adversarial attack</a></span></div><div class="content">英文题目：《Adaptive Perturbation for Adversarial Attack》 论文作者：YuanZheng,ZhangJie,JiangZhaoyan,LiLiangliang,ShanShiguang 发布于：IEEE Transactions on Pattern Analysis and Machine Intelligence 发布时间：2024/8 级别：CCF A 论文链接：10.1109/TPAMI.2024.3367773 摘要 In recent years, the security of deep learning models achieves more and more attentions with the rapid development of neural networks, which are vulnerable to adversarial examples.Almost all existing gradient-based attack methods use the sign function ...</div></div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/#content-inner">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/#content-inner">8</a><a class="extend next" rel="next" href="/page/2/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">LLM Security Group</div><div class="author-info-description">分享知识，认识世界</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">77</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">81</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">28</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/10/26/%E6%B8%B8%E4%BF%8A%E7%88%BD/2025-10-27/Multi-Turn%20Jailbreaking%20Large%20Language%20Models%20via%20Attention%20Shifting/" title="Multi-Turn Jailbreaking Large Language Models via Attention Shifting">Multi-Turn Jailbreaking Large Language Models via Attention Shifting</a><time datetime="2025-10-26T04:58:14.000Z" title="发表于 2025-10-26 12:58:14">2025-10-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/10/26/%E5%8F%A4%E4%B9%89%E7%BF%94/2025-10-27/Images%20are%20Achilles%E2%80%99%20Heel%20of%20Alignment%20Exploiting%20Visual%20Vulnerabilities%20for%20Jailbreaking%20Multimodal%20Large%20Language%20Models/" title="Images are Achilles’ Heel of Alignment: Exploiting Visual Vulnerabilities for Jailbreaking Multimodal Large Language Models">Images are Achilles’ Heel of Alignment: Exploiting Visual Vulnerabilities for Jailbreaking Multimodal Large Language Models</a><time datetime="2025-10-25T16:00:00.000Z" title="发表于 2025-10-26 00:00:00">2025-10-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/10/25/%E5%8F%A4%E4%B9%89%E7%BF%94/2025-10-27/Distraction%20is%20All%20You%20Need%20for%20Multimodal%20Large%20Language%20Model%20Jailbreaking/" title="Distraction is All You Need for Multimodal Large Language Model Jailbreaking">Distraction is All You Need for Multimodal Large Language Model Jailbreaking</a><time datetime="2025-10-24T16:00:00.000Z" title="发表于 2025-10-25 00:00:00">2025-10-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/10/21/%E4%BC%8D%E4%BF%8A/2025-10-24/SIDA%20Social%20Media%20Image%20Deepfake%20Detection,%20Localization%20and%20Explanation/" title="SIDA: Social Media Image Deepfake Detection, Localization and Explanation with Large Multimodal Model">SIDA: Social Media Image Deepfake Detection, Localization and Explanation with Large Multimodal Model</a><time datetime="2025-10-21T11:53:16.000Z" title="发表于 2025-10-21 19:53:16">2025-10-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/10/21/%E4%BC%8D%E4%BF%8A/2025-10-24/Generalized%20Diffusion%20Detector%20Mining%20Robust%20Features%20from%20Diffusion%20Models%20%20for%20Domain-Generalized%20Detection/" title="Generalized Diffusion Detector Mining Robust Features from Diffusion Models  for Domain-Generalized Detection">Generalized Diffusion Detector Mining Robust Features from Diffusion Models  for Domain-Generalized Detection</a><time datetime="2025-10-21T11:53:16.000Z" title="发表于 2025-10-21 19:53:16">2025-10-21</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            <a class="card-more-btn" href="/categories/" title="查看更多">
      <i class="fas fa-angle-right"></i></a>
          </div>
          <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/ADVERSARIAL-DEFENSE/"><span class="card-category-list-name">ADVERSARIAL DEFENSE</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/AI%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96/"><span class="card-category-list-name">AI系统优化</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Adversarial/"><span class="card-category-list-name">Adversarial</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Adversarial-Text-Generation/"><span class="card-category-list-name">Adversarial Text Generation</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Adversarial-attack/"><span class="card-category-list-name">Adversarial attack</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Attack/"><span class="card-category-list-name">Attack</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/BLACK-BOX-ATTACKS/"><span class="card-category-list-name">BLACK BOX ATTACKS</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/High-Confidence-Predictions-for-Unrecognizable-Images/"><span class="card-category-list-name">High Confidence Predictions for Unrecognizable Images</span><span class="card-category-list-count">1</span></a></li>
          </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/%E5%8F%8C%E8%B6%85%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/" style="font-size: 1.1em; color: #999">双超图卷积网络</a> <a href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" style="font-size: 1.5em; color: #99a9bf">强化学习</a> <a href="/tags/%E7%BC%96%E7%A0%81%E5%99%A8%E8%A7%A3%E7%A0%81%E5%99%A8/" style="font-size: 1.1em; color: #999">编码器解码器</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%BC%98%E5%8C%96/" style="font-size: 1.1em; color: #999">损失函数优化</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E4%BC%AA%E9%80%A0%E6%A3%80%E6%B5%8B/" style="font-size: 1.1em; color: #999">人脸伪造检测</a> <a href="/tags/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93/" style="font-size: 1.1em; color: #999">多智能体</a> <a href="/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%88%86%E6%95%A3/" style="font-size: 1.1em; color: #999">注意力分散</a> <a href="/tags/%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/" style="font-size: 1.1em; color: #999">监督微调</a> <a href="/tags/%E5%A4%A7%E5%9E%8B%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B/" style="font-size: 1.37em; color: #99a4b2">大型多模态模型</a> <a href="/tags/%E5%B1%82%E6%AC%A1%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88/" style="font-size: 1.1em; color: #999">层次特征融合</a> <a href="/tags/%E5%9F%BA%E6%9C%AC%E8%BF%AD%E4%BB%A3%E6%B3%95/" style="font-size: 1.1em; color: #999">基本迭代法</a> <a href="/tags/A3C%E7%AE%97%E6%B3%95/" style="font-size: 1.23em; color: #999ea6">A3C算法</a> <a href="/tags/%E7%89%B9%E5%BE%81%E5%A2%9E%E5%BC%BA/" style="font-size: 1.1em; color: #999">特征增强</a> <a href="/tags/GCG%E4%BC%98%E5%8C%96/" style="font-size: 1.1em; color: #999">GCG优化</a> <a href="/tags/RapidFuzz/" style="font-size: 1.1em; color: #999">RapidFuzz</a> <a href="/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8A%E5%8D%87/" style="font-size: 1.1em; color: #999">梯度上升</a> <a href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/" style="font-size: 1.37em; color: #99a4b2">大模型安全</a> <a href="/tags/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/" style="font-size: 1.1em; color: #999">遗传算法</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E4%BC%AA%E9%80%A0%E5%AE%9A%E4%BD%8D/" style="font-size: 1.23em; color: #999ea6">图像伪造定位</a> <a href="/tags/adversarial-example/" style="font-size: 1.1em; color: #999">adversarial example</a> <a href="/tags/PSA/" style="font-size: 1.1em; color: #999">PSA</a> <a href="/tags/%E5%AE%89%E5%85%A8%E5%AF%B9%E9%BD%90/" style="font-size: 1.23em; color: #999ea6">安全对齐</a> <a href="/tags/%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB/" style="font-size: 1.37em; color: #99a4b2">后门攻击</a> <a href="/tags/Adversarial-attack-ransfer-based-attack/" style="font-size: 1.1em; color: #999">Adversarial attack,ransfer-based attack</a> <a href="/tags/%E8%81%9A%E7%B1%BB/" style="font-size: 1.1em; color: #999">聚类</a> <a href="/tags/Search-R1/" style="font-size: 1.1em; color: #999">Search-R1</a> <a href="/tags/%E5%BE%AE%E8%B0%83/" style="font-size: 1.23em; color: #999ea6">微调</a> <a href="/tags/State-Space-Models/" style="font-size: 1.1em; color: #999">State Space Models</a> <a href="/tags/%E5%BC%B1%E7%9B%91%E7%9D%A3%E5%9B%BE%E5%83%8F%E4%BC%AA%E9%80%A0%E6%A3%80%E6%B5%8B/" style="font-size: 1.1em; color: #999">弱监督图像伪造检测</a> <a href="/tags/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7%E4%BC%AA%E9%80%A0%E6%A3%80%E6%B5%8B/" style="font-size: 1.23em; color: #999ea6">可解释性伪造检测</a> <a href="/tags/%E5%99%AA%E5%A3%B0%E5%BC%95%E5%AF%BC%E7%BD%91%E7%BB%9C/" style="font-size: 1.1em; color: #999">噪声引导网络</a> <a href="/tags/%E9%9F%B3%E9%A2%91%E8%B6%8A%E7%8B%B1%E6%94%BB%E5%87%BB/" style="font-size: 1.1em; color: #999">音频越狱攻击</a> <a href="/tags/%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95/" style="font-size: 1.1em; color: #999">进化算法</a> <a href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8%E5%AF%B9%E9%BD%90/" style="font-size: 1.1em; color: #999">大模型安全对齐</a> <a href="/tags/%E5%99%AA%E5%A3%B0%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0/" style="font-size: 1.1em; color: #999">噪声表示学习</a> <a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" style="font-size: 1.23em; color: #999ea6">多模态大型语言模型</a> <a href="/tags/%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88/" style="font-size: 1.1em; color: #999">特征融合</a> <a href="/tags/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%8D%8F%E4%BD%9C/" style="font-size: 1.37em; color: #99a4b2">多智能体协作</a> <a href="/tags/PRISM/" style="font-size: 1.1em; color: #999">PRISM</a> <a href="/tags/JailFuzzer/" style="font-size: 1.1em; color: #999">JailFuzzer</a></div></div><div class="card-widget card-archives">
    <div class="item-headline">
      <i class="fas fa-archive"></i>
      <span>归档</span>
      
    </div>
  
    <ul class="card-archive-list">
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2025/10/">
            <span class="card-archive-list-date">
              十月 2025
            </span>
            <span class="card-archive-list-count">17</span>
          </a>
        </li>
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2025/09/">
            <span class="card-archive-list-date">
              九月 2025
            </span>
            <span class="card-archive-list-count">14</span>
          </a>
        </li>
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2025/08/">
            <span class="card-archive-list-date">
              八月 2025
            </span>
            <span class="card-archive-list-count">45</span>
          </a>
        </li>
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2024/12/">
            <span class="card-archive-list-date">
              十二月 2024
            </span>
            <span class="card-archive-list-count">1</span>
          </a>
        </li>
      
    </ul>
  </div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站信息</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">77</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总浏览量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2025-10-27T02:27:54.130Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 By LLM Security Group</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.3</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script src="https://cdn.jsdelivr.net/gh/EmoryHuang/BlogBeautify@1.1/DynamicRibbon.min.js"></script><script src="https://cdn.jsdelivr.net/gh/EmoryHuang/BlogBeautify@1.1/star.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="输入关键词…" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>