<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>LLM Security Group 's Notes - 分享知识，认识世界</title><meta name="author" content="LLM Security Group"><meta name="copyright" content="LLM Security Group"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="分享知识，认识世界">
<meta property="og:type" content="website">
<meta property="og:title" content="LLM Security Group &#39;s Notes">
<meta property="og:url" content="https://fdreamer2002.github.io/page/2/index.html">
<meta property="og:site_name" content="LLM Security Group &#39;s Notes">
<meta property="og:description" content="分享知识，认识世界">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://fdreamer2002.github.io/img/butterfly-icon.png">
<meta property="article:author" content="LLM Security Group">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://fdreamer2002.github.io/img/butterfly-icon.png"><script type="application/ld+json"></script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://fdreamer2002.github.io/page/2/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":"ture","top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'LLM Security Group \'s Notes',
  isHighlightShrink: false,
  isToc: false,
  pageType: 'home'
}</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/EmoryHuang/BlogBeautify@1.1/scroll.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/EmoryHuang/BlogBeautify@1.1/gradient.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.7.0/style.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fontsource/jetbrains-mono@4.5.12/index.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><meta name="generator" content="Hexo 7.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">85</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">88</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">27</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><span> 类别分类</span></a></li><li><a class="site-page child" href="/authors/"><span> 作者分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> 关于</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">LLM Security Group 's Notes</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><span> 类别分类</span></a></li><li><a class="site-page child" href="/authors/"><span> 作者分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="site-info"><h1 id="site-title">LLM Security Group 's Notes</h1></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts nc" id="recent-posts"><div class="recent-post-items"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/10/26/%E6%B8%B8%E4%BF%8A%E7%88%BD/2025-10-27/Multi-Turn%20Jailbreaking%20Large%20Language%20Models%20via%20Attention%20Shifting/" title="Multi-Turn Jailbreaking Large Language Models via Attention Shifting">Multi-Turn Jailbreaking Large Language Models via Attention Shifting</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-26T04:58:14.000Z" title="发表于 2025-10-26 12:58:14">2025-10-26</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%B6%8A%E7%8B%B1%E6%94%BB%E5%87%BB/">越狱攻击</a></span></div><div class="content">英文题目：《Multi-Turn Jailbreaking Large Language Models via Attention Shifting》 中文题目：《通过注意力转移对大型语言模型进行多轮越狱攻击》 论文作者：Xiaohu Du, Fan Mo, Ming Wen, Tu Gu, Huadi Zheng, Hai Jin, Jie Shi 发布于： AAAI-25 发布时间：2025-04-11 级别：CCF-A 论文链接：https://doi.org/10.1609/aaai.v39i22.34553 论文代码：无  摘要 大型语言模型（LLM）在各种自然语言处理任务中取得了显着的性能，但也带来了安全和道德威胁，因此需要红队和对齐过程来加强它们的安全性。为了有效利用这些对齐的LLM，最近的研究引入了基于多轮对话的越狱攻击。这些攻击旨在通过上下文内容引导LLM生成有害或有偏见的内容。然而，多轮越狱有效性的根本原因仍然不清楚。现有的攻击通常侧重于优化查询和升级毒性以构建对话，缺乏对LLM固有漏洞的彻底分析。在本文中，我们首先对单轮越狱和多轮越狱之间的差异进行了深入分析...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/10/26/%E5%8F%A4%E4%B9%89%E7%BF%94/2025-10-27/Images%20are%20Achilles%E2%80%99%20Heel%20of%20Alignment%20Exploiting%20Visual%20Vulnerabilities%20for%20Jailbreaking%20Multimodal%20Large%20Language%20Models/" title="Images are Achilles’ Heel of Alignment: Exploiting Visual Vulnerabilities for Jailbreaking Multimodal Large Language Models">Images are Achilles’ Heel of Alignment: Exploiting Visual Vulnerabilities for Jailbreaking Multimodal Large Language Models</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-25T16:00:00.000Z" title="发表于 2025-10-26 00:00:00">2025-10-26</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%B6%8A%E7%8B%B1%E6%94%BB%E5%87%BB/">越狱攻击</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%B6%8A%E7%8B%B1%E6%94%BB%E5%87%BB/%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/">模型安全</a></span></div><div class="content">英文题目：《Images are Achilles’ Heel of Alignment: Exploiting Visual Vulnerabilities for Jailbreaking Multimodal Large Language Models》 中文题目：《图像是多模态对齐的阿喀琉斯之踵：利用视觉漏洞实现多模态大语言模型越狱》 论文作者：Yifan Li, Hangyu Guo, Kun Zhou, Wayne Xin Zhao, Ji-Rong Wen 单位：中国人民大学高瓴人工智能学院、信息学院、北京大数据管理与分析方法重点实验室 发布于：ECCV 2024（CCF B） 论文链接：https://arxiv.org/abs/2403.09792 代码链接：https://github.com/RUCAIBox/HADES  摘要 本文研究多模态大型语言模型（MLLMs）的安全对齐问题。我们对代表性MLLMs的无害性表现进行了系统性实证分析，发现图像输入会引发模型的对齐漏洞。基于此，我们提出名为hades的新型越狱方法，通过精心设计的图像隐藏并放大文本输入中的...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/10/25/%E5%8F%A4%E4%B9%89%E7%BF%94/2025-10-27/Distraction%20is%20All%20You%20Need%20for%20Multimodal%20Large%20Language%20Model%20Jailbreaking/" title="Distraction is All You Need for Multimodal Large Language Model Jailbreaking">Distraction is All You Need for Multimodal Large Language Model Jailbreaking</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-24T16:00:00.000Z" title="发表于 2025-10-25 00:00:00">2025-10-25</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/">模型安全</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/%E8%B6%8A%E7%8B%B1%E6%94%BB%E5%87%BB/">越狱攻击</a></span></div><div class="content">英文题目：《Distraction is All You Need for Multimodal Large Language Model Jailbreaking》 中文题目：《分散即一切：面向多模态大语言模型的越狱攻击方法研究》 论文作者：Zuopeng Yang, Jiluan Fan, Anli Yan, Erdun Gao, Xin Lin, Tao Li, Kanghua Mo, Changyu Dong 单位：广州大学、上海交通大学、阿德莱德大学 发布于：CVPR-2025（CCF  A） 发布时间：2025年2月 论文链接：https://arxiv.org/abs/2502.10794 代码链接：https://github.com/TeamPigeonLab/CS-DJ   摘要 多模态大语言模型（MLLMs）结合视觉与文本模态，展现了强大的跨模态理解能力，但复杂的视觉-文本交互也可能引入新的安全漏洞。本文提出了分散假设（Distraction Hypothesis），认为越狱攻击的关键并非图像内容本身，而是输入的复杂度与多样性对模型注意力的干扰作用。 基于此...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/10/24/%E6%B8%B8%E4%BF%8A%E7%88%BD/2025-10-27/FigStep%20Jailbreaking%20Large%20Vision-Language%20Models%20via%20Typographic%20Visual%20Prompts/" title="FigStep: Jailbreaking Large Vision-Language Models via Typographic Visual Prompts">FigStep: Jailbreaking Large Vision-Language Models via Typographic Visual Prompts</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-24T05:58:14.000Z" title="发表于 2025-10-24 13:58:14">2025-10-24</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%B6%8A%E7%8B%B1%E6%94%BB%E5%87%BB/">越狱攻击</a></span></div><div class="content">英文题目：《FigStep: Jailbreaking Large Vision-Language Models via Typographic Visual Prompts》 中文题目：《FigStep：通过排版式视觉提示实现大型视觉 - 语言模型越狱》 论文作者：Yichen Gong, Delong Ran, Jinyuan Liu, Conglei Wang, Tianshuo Cong, Anyu Wang, Sisi Duan, Xiaoyun Wang 发布于： AAAI-25 发布时间：2023-11-09 级别：CCF-A 论文链接：https://doi.org/10.48550/arXiv.2311.05608 论文代码：https://github.com/ThuCCSLab/FigStep  摘要 大型视觉-语言模型 (LVLM) 标志着人工智能 (AI) 领域内一个具有突破性的范式转变，它通过整合额外的模态（例如，图像）超越了大型语言模型 (LLM) 的能力。尽管取得了这一进展，但LVLM的安全性仍未得到充分探索，并且可能过度依赖于其底层LLM所宣称的...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/10/24/%E6%B8%B8%E4%BF%8A%E7%88%BD/2025-10-27/Con%20Instruction%20Universal%20Jailbreaking%20of%20Multimodal%20Large%20Language%20Models%20via%20Non-Textual%20Modalities/" title="Con Instruction: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities">Con Instruction: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-24T02:58:14.000Z" title="发表于 2025-10-24 10:58:14">2025-10-24</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%B6%8A%E7%8B%B1%E6%94%BB%E5%87%BB/">越狱攻击</a></span></div><div class="content">英文题目：《Con Instruction: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities》 中文题目：《Con Instruction：通过非文本模态实现多模态大型语言模型的通用越狱》 论文作者： Jiahui Geng, Thy Thy Tran, Preslav Nakov, Iryna Gurevych 发布于： ACL2025 发布时间：2025-05-31 级别：CCF-A 论文链接：https://doi.org/10.48550/arXiv.2506.00548 论文代码：https://github.com/UKPLab/acl2025-con-instruction  摘要 现有的针对多模态语言模型（MLLM）的攻击主要通过文本和对抗性图像来传递指令。相比之下，本文利用MLLM解释非文本指令的能力——特别是通过我们提出的新方法Con Instruction生成的对抗性图像或音频。我们优化对抗性样本，使其在嵌入空间中与目标指令紧密对齐，从...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/10/21/%E4%BC%8D%E4%BF%8A/2025-10-24/Generalized%20Diffusion%20Detector%20Mining%20Robust%20Features%20from%20Diffusion%20Models%20%20for%20Domain-Generalized%20Detection/" title="Generalized Diffusion Detector Mining Robust Features from Diffusion Models  for Domain-Generalized Detection">Generalized Diffusion Detector Mining Robust Features from Diffusion Models  for Domain-Generalized Detection</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-21T11:53:16.000Z" title="发表于 2025-10-21 19:53:16">2025-10-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%9B%BE%E5%83%8F%E4%BC%AA%E9%80%A0%E6%A3%80%E6%B5%8B/">图像伪造检测</a></span></div><div class="content">英文题目：《Generalized Diffusion Detector Mining Robust Features from Diffusion Models  for Domain-Generalized Detection》 中文题目：《广义扩散检测器：从扩散模型中挖掘出鲁棒的特征，用于领域广义检测》 论文作者：Boyong He; Yuxiang Ji; Qianwen Ye; Zhuoyue Tan; Liaoni Wu 发布于：CVPR 发布时间：2025-06 级别：CCF-A 论文链接：  10.1109/CVPR52734.2025.00927 论文代码：[heboyong/Generalized-Diffusion-Detector: CVPR2025] Generalized Diffusion Detector: Mining Robust Features from Diffusion Models for Domain-Generalized Detection  摘要 领域泛化 (DG) 目标检测旨在提升检测器在未见过场景下的性能。由于实际应用中的...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/10/21/%E4%BC%8D%E4%BF%8A/2025-10-24/SIDA%20Social%20Media%20Image%20Deepfake%20Detection,%20Localization%20and%20Explanation/" title="SIDA: Social Media Image Deepfake Detection, Localization and Explanation with Large Multimodal Model">SIDA: Social Media Image Deepfake Detection, Localization and Explanation with Large Multimodal Model</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-21T11:53:16.000Z" title="发表于 2025-10-21 19:53:16">2025-10-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%9B%BE%E5%83%8F%E4%BC%AA%E9%80%A0%E6%A3%80%E6%B5%8B/">图像伪造检测</a></span></div><div class="content">英文题目：《Social Media Image Deepfake Detection, Localization and Explanation with Large Multimodal Model》 中文题目：《SIDA:基于大型多模态模型对社交媒体图像深度伪造检测、定位与解释》 论文作者：Zhenglin Huang，Jinwei Hu，Xiangtai Li，Xiangtai Li，Xingyu Zhao，Bei Peng，Baoyuan Wu，Xiaowei Huang，Guangliang Cheng 发布于：CVPR 发布时间：2025-06 级别：CCF-A 论文链接： 10.1109/CVPR52734.2025.02685 论文代码：https://github.com/hzlsaber/SIDA  摘要 生成模型在创建高度逼真图像方面的快速进展， 对错误信息传播构成了重大风险。例如，当合成图像在社交媒体上分享时，可能会误导大量受众并侵蚀对数字内容的信任，导致严重后果。尽管取得了一些进展，学术界尚未为社交媒体创建一个大型且多样化的 深度伪造检测数据集，也尚未...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/10/21/%E4%BC%8D%E4%BF%8A/2025-10-24/Language-guided%20Hierarchical%20Fine-grained%20Image%20Forgery/" title="Language-guided Hierarchical Fine-grained Image Forgery Detection and Localization">Language-guided Hierarchical Fine-grained Image Forgery Detection and Localization</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-21T11:53:16.000Z" title="发表于 2025-10-21 19:53:16">2025-10-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%9B%BE%E5%83%8F%E4%BC%AA%E9%80%A0%E6%A3%80%E6%B5%8B/">图像伪造检测</a></span></div><div class="content">英文题目：《Language-guided Hierarchical Fine-grained Image Forgery Detection and Localization》 中文题目：《语言引导的分层细粒度图像伪造检测与定位》 论文作者：Xiao Guo，Xiaohong Liu，Iacopo Masi，Xiaoming Liu 发布于：IJCV 发布时间：2025-12-10 级别：CCF-A 论文链接： https://doi.org/10.1007/s11263-024-02255-9 论文代码：https://github.com/CHELSEA234/HiFi_IFDL  摘要 CNN 合成和图像编辑领域生成的图像的伪造属性差异很大，这种差异使得统一的图像伪造检测和定位 (IFDL) 具有挑战性。为此，我们提出了一种用于 IFDL 表示学习的分层细粒度公式。具体而言，我们首先用不同级别的多个标签表示被篡改图像的伪造属性。然后，我们利用它们之间的层次依赖关系在这些级别上进行细粒度分类。因此，该算法能够学习全面的特征和不同伪造属性固有的层次结构，从而改进 IFDL 表...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/10/20/%E6%98%93%E5%AD%90%E6%96%87/%E7%AE%97%E6%B3%95%E7%B2%BE%E8%AF%BB/%E5%AF%B9%E6%8A%97%E6%80%A7%E6%94%BB%E5%87%BB%E6%A6%82%E8%BF%B0/" title="对抗性攻击概述">对抗性攻击概述</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-20T08:00:21.000Z" title="发表于 2025-10-20 16:00:21">2025-10-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AF%B9%E6%8A%97%E6%80%A7%E6%94%BB%E5%87%BB%E6%A6%82%E8%BF%B0/">对抗性攻击概述</a></span></div><div class="content">   </div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/10/20/%E6%98%93%E5%AD%90%E6%96%87/2025-10-20/Adaptive-Perturbation-for-Adversarial-Attack/" title="’Adaptive Perturbation for Adversarial Attack'">’Adaptive Perturbation for Adversarial Attack'</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-10-19T16:00:00.000Z" title="发表于 2025-10-20 00:00:00">2025-10-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Adversarial-attack/">Adversarial attack</a></span></div><div class="content">英文题目：《Adaptive Perturbation for Adversarial Attack》 论文作者：YuanZheng,ZhangJie,JiangZhaoyan,LiLiangliang,ShanShiguang 发布于：IEEE Transactions on Pattern Analysis and Machine Intelligence 发布时间：2024/8 级别：CCF A 论文链接：10.1109/TPAMI.2024.3367773 摘要 In recent years, the security of deep learning models achieves more and more attentions with the rapid development of neural networks, which are vulnerable to adversarial examples.Almost all existing gradient-based attack methods use the sign function in the ...</div></div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/#content-inner">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/#content-inner">9</a><a class="extend next" rel="next" href="/page/3/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">LLM Security Group</div><div class="author-info-description">分享知识，认识世界</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">85</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">88</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">27</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/04/%E4%BC%8D%E4%BF%8A/2025-11-07/SNIS%20A%20Signal%20Noise%20Separation-Based%20Network%20%20for%20Post-Processed%20Image%20Forgery%20Detection/" title="SNIS: A Signal Noise Separation-Based Network  for Post-Processed Image Forgery Detection">SNIS: A Signal Noise Separation-Based Network  for Post-Processed Image Forgery Detection</a><time datetime="2025-11-04T11:53:16.000Z" title="发表于 2025-11-04 19:53:16">2025-11-04</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/03/%E4%BC%8D%E4%BF%8A/2025-11-07/Identification%20of%20image%20global%20processing%20operator%20chain%20based%20on%20feature%20decoupling/" title="Identification of image global processing operator chain based on feature decoupling">Identification of image global processing operator chain based on feature decoupling</a><time datetime="2025-11-03T11:53:16.000Z" title="发表于 2025-11-03 19:53:16">2025-11-03</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/03/%E4%BC%8D%E4%BF%8A/2025-11-07/Is%20Artificial%20Intelligence%20Generated%20Image%20Detection%20a%20Solved%20Problem/" title="Is Artificial Intelligence Generated Image Detection a Solved Problem">Is Artificial Intelligence Generated Image Detection a Solved Problem</a><time datetime="2025-11-03T11:53:16.000Z" title="发表于 2025-11-03 19:53:16">2025-11-03</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/01/%E6%B8%B8%E4%BF%8A%E7%88%BD/2025-11-03/MASTERKEY%20Automated%20Jailbreaking%20of%20Large%20Language%20Model%20Chatbots/" title="MASTERKEY: Automated Jailbreaking of Large Language Model Chatbots">MASTERKEY: Automated Jailbreaking of Large Language Model Chatbots</a><time datetime="2025-11-01T12:58:14.000Z" title="发表于 2025-11-01 20:58:14">2025-11-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/10/31/%E6%B8%B8%E4%BF%8A%E7%88%BD/2025-11-03/SELFDEFEND%20LLMs%20Can%20Defend%20Themselves%20against%20Jailbreaking%20in%20a%20Practical%20Manner/" title="SELFDEFEND: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner">SELFDEFEND: LLMs Can Defend Themselves against Jailbreaking in a Practical Manner</a><time datetime="2025-10-31T12:58:14.000Z" title="发表于 2025-10-31 20:58:14">2025-10-31</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            <a class="card-more-btn" href="/categories/" title="查看更多">
      <i class="fas fa-angle-right"></i></a>
          </div>
          <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/ADVERSARIAL-DEFENSE/"><span class="card-category-list-name">ADVERSARIAL DEFENSE</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/AI%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96/"><span class="card-category-list-name">AI系统优化</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Adversarial/"><span class="card-category-list-name">Adversarial</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Adversarial-Text-Generation/"><span class="card-category-list-name">Adversarial Text Generation</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Adversarial-attack/"><span class="card-category-list-name">Adversarial attack</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Attack/"><span class="card-category-list-name">Attack</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/BLACK-BOX-ATTACKS/"><span class="card-category-list-name">BLACK BOX ATTACKS</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/High-Confidence-Predictions-for-Unrecognizable-Images/"><span class="card-category-list-name">High Confidence Predictions for Unrecognizable Images</span><span class="card-category-list-count">1</span></a></li>
          </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/Convolutional-Neural-Network/" style="font-size: 1.1em; color: #999">Convolutional Neural Network</a> <a href="/tags/%E5%99%AA%E5%A3%B0%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0/" style="font-size: 1.1em; color: #999">噪声表示学习</a> <a href="/tags/A3C%E7%AE%97%E6%B3%95/" style="font-size: 1.3em; color: #99a1ac">A3C算法</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E4%BC%AA%E9%80%A0%E6%A3%80%E6%B5%8B/" style="font-size: 1.1em; color: #999">人脸伪造检测</a> <a href="/tags/fast-gradient-sign-method/" style="font-size: 1.1em; color: #999">fast gradient sign method</a> <a href="/tags/%E8%B6%8A%E7%8B%B1%E5%88%86%E6%9E%90%E4%B8%8E%E6%A6%82%E5%BF%B5/" style="font-size: 1.1em; color: #999">越狱分析与概念</a> <a href="/tags/%E9%9F%B3%E9%A2%91%E8%B6%8A%E7%8B%B1%E6%94%BB%E5%87%BB/" style="font-size: 1.1em; color: #999">音频越狱攻击</a> <a href="/tags/%E9%80%9A%E8%BF%87%E5%AE%9E%E4%BE%8B%E7%BA%A7%E4%B8%BB%E6%88%90%E5%88%86%E7%A7%BB%E9%99%A4%E5%A2%9E%E5%BC%BA%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%B2%81%E6%A3%92%E6%80%A7/" style="font-size: 1.1em; color: #999">通过实例级主成分移除增强语言模型的鲁棒性</a> <a href="/tags/Image-Recognition/" style="font-size: 1.1em; color: #999">Image Recognition</a> <a href="/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%88%86%E6%95%A3/" style="font-size: 1.1em; color: #999">注意力分散</a> <a href="/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/" style="font-size: 1.3em; color: #99a1ac">注意力机制</a> <a href="/tags/%E8%81%9A%E7%B1%BB/" style="font-size: 1.1em; color: #999">聚类</a> <a href="/tags/PRISM/" style="font-size: 1.1em; color: #999">PRISM</a> <a href="/tags/%E7%AF%A1%E6%94%B9%E9%93%BE%E5%8F%96%E8%AF%81/" style="font-size: 1.3em; color: #99a1ac">篡改链取证</a> <a href="/tags/%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/" style="font-size: 1.1em; color: #999">监督微调</a> <a href="/tags/%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB/" style="font-size: 1.5em; color: #99a9bf">后门攻击</a> <a href="/tags/%E4%BF%A1%E5%99%AA%E5%88%86%E7%A6%BB/" style="font-size: 1.1em; color: #999">信噪分离</a> <a href="/tags/%E7%AF%A1%E6%94%B9%E6%96%B9%E6%B3%95%E8%AF%86%E5%88%AB/" style="font-size: 1.1em; color: #999">篡改方法识别</a> <a href="/tags/Differential-Evolution/" style="font-size: 1.1em; color: #999">Differential Evolution</a> <a href="/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 1.3em; color: #99a1ac">循环神经网络</a> <a href="/tags/%E7%89%B9%E5%BE%81%E5%A2%9E%E5%BC%BA/" style="font-size: 1.1em; color: #999">特征增强</a> <a href="/tags/PUZZLED/" style="font-size: 1.1em; color: #999">PUZZLED</a> <a href="/tags/%E5%8F%8C%E8%B6%85%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/" style="font-size: 1.1em; color: #999">双超图卷积网络</a> <a href="/tags/%E5%8F%8C%E6%B5%81%E6%8F%90%E5%8F%96/" style="font-size: 1.1em; color: #999">双流提取</a> <a href="/tags/TextGrad/" style="font-size: 1.1em; color: #999">TextGrad</a> <a href="/tags/adversarial-example/" style="font-size: 1.1em; color: #999">adversarial example</a> <a href="/tags/%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95/" style="font-size: 1.1em; color: #999">进化算法</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8/" style="font-size: 1.1em; color: #999">模型安全</a> <a href="/tags/%E5%BC%B1%E7%9B%91%E7%9D%A3%E5%9B%BE%E5%83%8F%E4%BC%AA%E9%80%A0%E6%A3%80%E6%B5%8B/" style="font-size: 1.1em; color: #999">弱监督图像伪造检测</a> <a href="/tags/Search-R1/" style="font-size: 1.1em; color: #999">Search-R1</a> <a href="/tags/adaptive-perturbation/" style="font-size: 1.1em; color: #999">adaptive perturbation</a> <a href="/tags/%E5%A4%9A%E8%BD%AE%E8%B6%8A%E7%8B%B1/" style="font-size: 1.1em; color: #999">多轮越狱</a> <a href="/tags/%E5%AE%89%E5%85%A8%E5%AF%B9%E9%BD%90/" style="font-size: 1.3em; color: #99a1ac">安全对齐</a> <a href="/tags/I-GCG/" style="font-size: 1.1em; color: #999">I-GCG</a> <a href="/tags/State-Space-Models/" style="font-size: 1.1em; color: #999">State Space Models</a> <a href="/tags/%E4%B8%80%E8%87%B4%E6%80%A7%E5%AD%A6%E4%B9%A0/" style="font-size: 1.1em; color: #999">一致性学习</a> <a href="/tags/%E5%B1%82%E6%AC%A1%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88/" style="font-size: 1.1em; color: #999">层次特征融合</a> <a href="/tags/Adversarial-attack-ransfer-based-attack/" style="font-size: 1.1em; color: #999">Adversarial attack,ransfer-based attack</a> <a href="/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8A%E5%8D%87/" style="font-size: 1.1em; color: #999">梯度上升</a> <a href="/tags/%E5%9F%BA%E4%BA%8ECatmullRom%E6%A0%B7%E6%9D%A1%E5%9B%9E%E5%BD%92/" style="font-size: 1.1em; color: #999">基于CatmullRom样条回归</a></div></div><div class="card-widget card-archives">
    <div class="item-headline">
      <i class="fas fa-archive"></i>
      <span>归档</span>
      
    </div>
  
    <ul class="card-archive-list">
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2025/11/">
            <span class="card-archive-list-date">
              十一月 2025
            </span>
            <span class="card-archive-list-count">4</span>
          </a>
        </li>
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2025/10/">
            <span class="card-archive-list-date">
              十月 2025
            </span>
            <span class="card-archive-list-count">23</span>
          </a>
        </li>
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2025/09/">
            <span class="card-archive-list-date">
              九月 2025
            </span>
            <span class="card-archive-list-count">13</span>
          </a>
        </li>
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2025/08/">
            <span class="card-archive-list-date">
              八月 2025
            </span>
            <span class="card-archive-list-count">45</span>
          </a>
        </li>
      
    </ul>
  </div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站信息</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">85</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总浏览量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2025-11-08T03:40:51.526Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 By LLM Security Group</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.3</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script src="https://cdn.jsdelivr.net/gh/EmoryHuang/BlogBeautify@1.1/DynamicRibbon.min.js"></script><script src="https://cdn.jsdelivr.net/gh/EmoryHuang/BlogBeautify@1.1/star.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="输入关键词…" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>